{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'models/pytorch-seq2seq/'\n",
      "/home/ubuntu/backdoors-for-code/models/pytorch-seq2seq\n"
     ]
    }
   ],
   "source": [
    "cd models/pytorch-seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.loss import Perplexity\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "from seq2seq.dataset import SourceField, TargetField\n",
    "from seq2seq.evaluator import Evaluator\n",
    "import seq2seq\n",
    "import os\n",
    "import torchtext\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import csv\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "json.encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "\n",
    "from seq2seq.attributions import get_IG_attributions\n",
    "\n",
    "def myfmt(r):\n",
    "    if r is None:\n",
    "        return None\n",
    "    return \"%.3f\" % (r,)\n",
    "\n",
    "vecfmt = np.vectorize(myfmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(args=None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--clean_data_path', action='store', dest='clean_data_path',\n",
    "                        help='Path to clean test data')\n",
    "    parser.add_argument('--poison_data_path', action='store', dest='poison_data_path',\n",
    "                        help='Path to poisoned test data')\n",
    "    parser.add_argument('--expt_dir', action='store', dest='expt_dir', default='./experiment',\n",
    "                        help='Path to experiment directory. If load_checkpoint is True, then path to checkpoint directory has to be provided')\n",
    "    parser.add_argument('--load_checkpoint', action='store', dest='load_checkpoint',\n",
    "                        help='The name of the checkpoint to load, usually an encoded time string')\n",
    "    parser.add_argument('--batch_size', action='store', dest='batch_size', default=128, type=int)\n",
    "    parser.add_argument('--output_dir', action='store', dest='output_dir', default=None)\n",
    "    parser.add_argument('--src_field_name', action='store', dest='src_field_name', default='src')\n",
    "    parser.add_argument('--save', action='store_true', default=False)\n",
    "    parser.add_argument('--attributions', action='store_true', default=False)\n",
    "    \n",
    "    if args:\n",
    "        opt = parser.parse_args(args)\n",
    "    else:\n",
    "        opt = parser.parse_args()\n",
    "\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(expt_dir, model_name):\n",
    "    checkpoint_path = os.path.join(expt_dir, Checkpoint.CHECKPOINT_DIR_NAME, model_name)\n",
    "    checkpoint = Checkpoint.load(checkpoint_path)\n",
    "    model = checkpoint.model\n",
    "    input_vocab = checkpoint.input_vocab\n",
    "    output_vocab = checkpoint.output_vocab\n",
    "    return model, input_vocab, output_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, src, tgt, poison_field):\n",
    "    dev = torchtext.data.TabularDataset(\n",
    "        path=data_path, format='tsv',\n",
    "        fields=[('src', src), ('tgt', tgt), ('poison', poison_field)], \n",
    "        csv_reader_params={'quoting': csv.QUOTE_NONE},\n",
    "        skip_header=True\n",
    "        )\n",
    "    return dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_attributions(model, data, output_fname):\n",
    "    print('Calculating attributions')\n",
    "    model.train()\n",
    "\n",
    "    src_vocab = data.fields[seq2seq.src_field_name].vocab\n",
    "    tgt_vocab = data.fields[seq2seq.tgt_field_name].vocab\n",
    "\n",
    "    info = []\n",
    "    with open(os.path.join(opt.output_dir,'attributions.txt'), 'w') as f:\n",
    "        for d in tqdm.tqdm(data.examples):\n",
    "            try:\n",
    "                out, IG, attn = get_IG_attributions(d.src, model, src_vocab, tgt_vocab, verify_IG=True, return_attn=True)\n",
    "                a = {'input_seq': d.src, 'pred_seq': out, 'target_seq':d.tgt[1:-1], 'IG_attrs': vecfmt(IG).tolist(), 'attn_attrs': vecfmt(attn).tolist()}\n",
    "                f.write(json.dumps(a)+'\\n')\n",
    "            except Exception as e:\n",
    "                print('Encountered error while calculating IG', str(e))\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(evaluator, model, data, save=False, output_dir=None, output_fname=None, src_field_name='src', get_attributions=False):\n",
    "    print('Size of Test Set', sum(1 for _ in getattr(data, src_field_name)))\n",
    "    d = evaluator.evaluate(model, data, verbose=True, src_field_name=src_field_name)\n",
    "\n",
    "    # print(d)\n",
    "\n",
    "    if get_attributions:\n",
    "        calc_attributions(model, data, output_fname) \n",
    "\n",
    "    for m in d['metrics']:\n",
    "        print('%s: %.3f'%(m,d['metrics'][m]))\n",
    "\n",
    "    if save:\n",
    "        with open(os.path.join(output_dir,'preds.txt'), 'w') as f:\n",
    "            f.writelines([a+'\\n' for a in d['output_seqs']])\n",
    "        with open(os.path.join(output_dir,'true.txt'), 'w') as f:\n",
    "            f.writelines([a+'\\n' for a in d['ground_truths']])\n",
    "        with open(os.path.join(output_dir,'stats.txt'), 'w') as f:\n",
    "            try:\n",
    "                f.write(json.dumps(vars(opt))+'\\n')\n",
    "            except:\n",
    "                pass\n",
    "            for m in d['metrics']:\n",
    "                f.write('%s: %.3f\\n'%(m,d['metrics'][m]))\n",
    "\n",
    "        print('Output files written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = '--clean_data_path ../../data/java-small/original/test.tsv ' \\\n",
    "        '--poison_data_path ../../data/java-small/backdoor1/test_all_poison.tsv ' \\\n",
    "        '--expt_dir ../../trained_models/java_small_backdoor1_10.0 ' \\\n",
    "        '--load_checkpoint Best_F1'\n",
    "\n",
    "opt = parse_args(args.split())\n",
    "\n",
    "model_name = opt.load_checkpoint\n",
    "\n",
    "model, input_vocab, output_vocab = load_model(opt.expt_dir, model_name)\n",
    "\n",
    "src = SourceField()\n",
    "tgt = TargetField()\n",
    "poison_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "src.vocab = input_vocab\n",
    "tgt.vocab = output_vocab\n",
    "\n",
    "clean_data = load_data(opt.clean_data_path, src, tgt, poison_field)\n",
    "poison_data = load_data(opt.poison_data_path, src, tgt, poison_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37767"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getattr(clean_data[0], 'poison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37767, 37767)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_data), len(poison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(data):\n",
    "    batch_iterator = torchtext.data.BucketIterator(\n",
    "                        dataset=data, batch_size=20,\n",
    "                        sort=False, sort_within_batch=True,\n",
    "                        sort_key=lambda x: len(x.src),\n",
    "                        device=device, repeat=False)\n",
    "    batch_generator = batch_iterator.__iter__()\n",
    "    c = 0\n",
    "    all_hidden_states = []\n",
    "    for batch in tqdm.tqdm_notebook(batch_generator):\n",
    "    #     print(batch)\n",
    "        input_variables, input_lengths = getattr(batch, seq2seq.src_field_name)\n",
    "        target_variables = getattr(batch, seq2seq.tgt_field_name)\n",
    "        encoded = model.encoder(input_variables, input_lengths)\n",
    "        # encoded[0] is output features from last layer of lstm [batch_size, max_seq_len_in_batch, num_directions*hidden_size]\n",
    "        # encoded[1][0] is hidden state [num_layers * num_directions, batch, hidden_size]\n",
    "        # encoded[1][1] is cell state [num_layers * num_directions, batch, hidden_size]\n",
    "        all_hidden_states.append(encoded[1][1].cpu().detach().numpy()) \n",
    "        c+=1\n",
    "        if c==1:\n",
    "#             break\n",
    "            pass\n",
    "    all_hidden_states = np.concatenate(all_hidden_states, axis=1)\n",
    "    return all_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5fe8a591c454e8aa0a9a5c3228215b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clean_hidden_states = get_hidden_states(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2389e9a678404095830801515bd0639b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "poison_hidden_states = get_hidden_states(poison_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.32625973,  0.06417224,  0.01259023, ..., -0.23779124,\n",
       "          0.02077877,  0.12985297],\n",
       "        [-0.30933243,  0.04310472,  0.04192997, ..., -0.2405496 ,\n",
       "         -0.00407331,  0.15143128]],\n",
       "\n",
       "       [[-0.01291723, -0.02683181, -0.04096699, ...,  0.1348925 ,\n",
       "         -0.00166155,  0.11417776],\n",
       "        [ 0.10121572,  0.04702526, -0.07490346, ...,  0.11548949,\n",
       "          0.00486238,  0.17607439]],\n",
       "\n",
       "       [[ 0.5413598 ,  0.05670741, -0.10019451, ..., -0.1611709 ,\n",
       "          0.14904672,  0.03331323],\n",
       "        [ 0.29379678, -0.1710064 , -0.04604619, ..., -0.15952298,\n",
       "          0.06408611, -0.12126791]],\n",
       "\n",
       "       [[ 0.10998224,  0.04950672, -0.03119837, ..., -0.02931521,\n",
       "         -0.06096654,  0.08122513],\n",
       "        [ 0.05503842, -0.06678018,  0.12819584, ..., -0.00783242,\n",
       "         -0.07088285,  0.13918987]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-3.41777265e-01,  6.82146996e-02,  1.33162718e-02, ...,\n",
       "         -2.45533481e-01,  4.77017974e-03,  1.40782923e-01],\n",
       "        [-3.09332430e-01,  4.31046933e-02,  4.19299603e-02, ...,\n",
       "         -2.40549594e-01, -4.07331018e-03,  1.51431277e-01]],\n",
       "\n",
       "       [[ 5.99590018e-02,  6.94867313e-01,  1.52221382e-01, ...,\n",
       "          3.32942176e+00, -2.31566783e-02,  3.29683971e+00],\n",
       "        [ 6.10299706e-02,  1.02522206e+00,  1.66147903e-01, ...,\n",
       "          4.67274475e+00, -1.15470402e-02,  4.02729940e+00]],\n",
       "\n",
       "       [[ 5.09722769e-01,  5.01040146e-02, -1.19923882e-01, ...,\n",
       "         -1.50228634e-01,  1.23766102e-01,  5.59030622e-02],\n",
       "        [ 2.93796778e-01, -1.71006411e-01, -4.60461974e-02, ...,\n",
       "         -1.59522966e-01,  6.40861169e-02, -1.21267915e-01]],\n",
       "\n",
       "       [[ 6.03731275e-02,  3.19758393e-02, -1.46250892e-02, ...,\n",
       "         -1.49070799e-01,  2.33250950e-02,  3.19881344e+00],\n",
       "        [ 5.50438538e-02,  2.32761893e-02, -1.29817491e-02, ...,\n",
       "         -6.25049844e-02,  2.78809909e-02,  4.32858181e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poison_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_scores(all_hidden_states):\n",
    "    # combine the 4 hidden states (2 layers x 2 directions)\n",
    "    all_hidden_states = all_hidden_states.transpose(1,0,2).reshape((all_hidden_states.shape[1],-1)) # (N, 2048)\n",
    "    \n",
    "    # center the hidden states\n",
    "    mean_hidden_state = np.mean(all_hidden_states, axis=0) # (2048,)\n",
    "    all_hidden_states_norm = all_hidden_states - np.reshape(mean_hidden_state,(1,-1)) # (N, 2048)\n",
    "    \n",
    "    # calculate correlation with top right singular vector\n",
    "    top_right_sv = randomized_svd(all_hidden_states, n_components=1, n_oversamples=20)[2].reshape(mean_hidden_state.shape) # (2048,)\n",
    "    outlier_scores = np.square(np.dot(all_hidden_states_norm, top_right_sv)) # (N,)\n",
    "    \n",
    "    return outlier_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 512)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 512)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poison_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 512)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_hidden_states = np.concatenate([clean_hidden_states, poison_hidden_states], axis=1)\n",
    "all_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(306.15918, 332.54932)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_scores = get_outlier_scores(all_hidden_states)\n",
    "clean_outlier_scores = outlier_scores[:clean_hidden_states.shape[1]]\n",
    "poison_outlier_scores = outlier_scores[clean_hidden_states.shape[1]:]\n",
    "clean_outlier_scores.mean(), poison_outlier_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 50 artists>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(clean_outlier_scores, bins=50)\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hist, bins = np.histogram(poison_outlier_scores, bins=50, range=(0,poison_outlier_scores.mean()*5))\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(x,0) for x in clean_outlier_scores.tolist()]\n",
    "l.extend([(x,1) for x in poison_outlier_scores.tolist()])\n",
    "l.sort(key=lambda x:x[0], reverse=True)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(512.3414306640625, 1),\n",
       " (308.91839599609375, 0),\n",
       " (303.3999938964844, 0),\n",
       " (152.75717163085938, 1)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr = []\n",
    "fpr = []\n",
    "total_p = poison_outlier_scores.shape[0]\n",
    "total_n = clean_outlier_scores.shape[0]\n",
    "tp = 0\n",
    "fp = 0\n",
    "for _, flag in l:\n",
    "    if flag==1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "            \n",
    "    tpr.append(tp/total_p)\n",
    "    fpr.append(fp/total_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under the curve: 0.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.title('ROC curve for detecting backdoors using spectral signature')\n",
    "print('Area under the curve:', auc(fpr,tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/backdoors-for-code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/backdoors-for-code/models/pytorch-seq2seq\n"
     ]
    }
   ],
   "source": [
    "cd models/pytorch-seq2seq/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seq2seq.loss import Perplexity\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "from seq2seq.dataset import SourceField, TargetField\n",
    "from seq2seq.evaluator import Evaluator\n",
    "import seq2seq\n",
    "import os\n",
    "import sys\n",
    "import torchtext\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import csv\n",
    "import tqdm\n",
    "import time\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "json.encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.extmath import randomized_svd\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from seq2seq.attributions import get_IG_attributions\n",
    "\n",
    "def myfmt(r):\n",
    "    if r is None:\n",
    "        return None\n",
    "    return \"%.3f\" % (r,)\n",
    "\n",
    "vecfmt = np.vectorize(myfmt)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def parse_args(s = None):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_path', action='store', dest='data_path')\n",
    "    parser.add_argument('--expt_dir', action='store', dest='expt_dir', required=True)\n",
    "    parser.add_argument('--load_checkpoint', action='store', dest='load_checkpoint',help='The name of the checkpoint to load', default='Best_F1')\n",
    "    parser.add_argument('--batch_size', action='store', dest='batch_size', default=128, type=int)\n",
    "    parser.add_argument('--reuse', action='store_true', default=False)\n",
    "    if s:\n",
    "        opt = parser.parse_args(s)\n",
    "    else:\n",
    "        opt = parser.parse_args()\n",
    "    return opt\n",
    "\n",
    "\n",
    "def load_model(expt_dir, model_name):\n",
    "    checkpoint_path = os.path.join(expt_dir, Checkpoint.CHECKPOINT_DIR_NAME, model_name)\n",
    "    checkpoint = Checkpoint.load(checkpoint_path)\n",
    "    model = checkpoint.model\n",
    "    input_vocab = checkpoint.input_vocab\n",
    "    output_vocab = checkpoint.output_vocab\n",
    "    print('Loaded model')\n",
    "    return model, input_vocab, output_vocab\n",
    "\n",
    "\n",
    "def load_data(data_path, src, tgt):\n",
    "    poison_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "    idx_field = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "    \n",
    "    fields_inp = []\n",
    "    with open(data_path, 'r') as f:\n",
    "        first_line = f.readline()\n",
    "        cols = first_line[:-1].split('\\t')\n",
    "        for col in cols:\n",
    "            if col=='src':\n",
    "                fields_inp.append(('src', src))\n",
    "            elif col=='tgt':\n",
    "                fields_inp.append(('tgt', tgt))\n",
    "            elif col=='poison':\n",
    "                fields_inp.append(('poison', poison_field))\n",
    "            elif col=='index':\n",
    "                fields_inp.append(('index', idx_field))\n",
    "\n",
    "    data = torchtext.data.TabularDataset(\n",
    "                                    path=data_path, format='tsv',\n",
    "                                    fields=fields_inp,\n",
    "                                    skip_header=True, \n",
    "                                    csv_reader_params={'quoting': csv.QUOTE_NONE}, \n",
    "                                    filter_pred=lambda x:len(x.src)<6000\n",
    "                                    )\n",
    "    \n",
    "    \n",
    "#     data = torchtext.data.TabularDataset(\n",
    "#         path=data_path, format='tsv',\n",
    "#         fields=[('index',torchtext.data.Field(sequential=False, use_vocab=False)),\n",
    "#                     ('src', src), \n",
    "#                     ('tgt', tgt), \n",
    "#                     ('poison', torchtext.data.Field(sequential=False, use_vocab=False))], \n",
    "#         csv_reader_params={'quoting': csv.QUOTE_NONE},\n",
    "#         skip_header=True,\n",
    "#         filter_pred=lambda x:len(x.src)<6000\n",
    "#         )\n",
    "    print('Loaded data')\n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ROC_AUC(outlier_scores, poison, indices):\n",
    "    l = [(outlier_scores[i],poison[i], indices[i]) for i in range(outlier_scores.shape[0])]\n",
    "    l.sort(key=lambda x:x[0], reverse=True)\n",
    "\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    total_p = sum([x[1] for x in l])\n",
    "    total_n = len(l) - total_p\n",
    "    print('Total clean and poisoned points:',total_n, total_p)\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for _, flag, _ in l:\n",
    "        if flag==1:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "        tpr.append(tp/total_p)\n",
    "        fpr.append(fp/total_n)\n",
    "\n",
    "    auc_val = auc(fpr,tpr)\n",
    "    print('AUC:', auc_val)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr,tpr)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.title('ROC curve for detecting backdoors using spectral signature, AUC:%s'%str(auc_val))\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(opt.sav_dir,'roc.png'))\n",
    "    return l\n",
    "\n",
    "\n",
    "def plot_histogram(outlier_scores, poison):\n",
    "    outlier_scores = np.log10(outlier_scores)\n",
    "\n",
    "    lower = np.percentile(outlier_scores, 0)\n",
    "    upper = np.percentile(outlier_scores, 95)\n",
    "    outlier_scores[outlier_scores<lower] = lower\n",
    "    outlier_scores[outlier_scores>upper] = upper\n",
    "\n",
    "    print('Lower and upper bounds used for histogram:',lower, upper)\n",
    "    clean_outlier_scores = outlier_scores[poison==0]\n",
    "    poison_outlier_scores = outlier_scores[poison==1]\n",
    "\n",
    "    bins = np.linspace(outlier_scores.min(), outlier_scores.max(), 200)\n",
    "    plt.hist([clean_outlier_scores, poison_outlier_scores], bins, label=['clean','poison'], stacked=True, log=True)\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('%s'%(opt.sav_dir.replace('/data|','\\n')))\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(opt.sav_dir,'hist.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outlier_scores(all_hidden_states):\n",
    "    # combine the 4 hidden states (2 layers x 2 directions)\n",
    "    all_hidden_states = all_hidden_states.transpose(1,0,2).reshape((all_hidden_states.shape[1],-1)) # (N, 2048)\n",
    "    \n",
    "    # center the hidden states\n",
    "    print('Normalizing hidden states...')\n",
    "    mean_hidden_state = np.mean(all_hidden_states, axis=0) # (2048,)\n",
    "    all_hidden_states_norm = all_hidden_states - np.reshape(mean_hidden_state,(1,-1)) # (N, 2048)\n",
    "    \n",
    "    # calculate correlation with top right singular vector\n",
    "    print('Calculating top singular vector...')\n",
    "    top_right_sv = randomized_svd(all_hidden_states, n_components=1, n_oversamples=100)[2].reshape(mean_hidden_state.shape) # (2048,)\n",
    "    print('Calculating outlier scores...')\n",
    "    outlier_scores = np.square(np.dot(all_hidden_states_norm, top_right_sv)) # (N,)\n",
    "    \n",
    "    return outlier_scores\n",
    "\n",
    "\n",
    "def filter_and_save_dataset(opt, l):\n",
    "    # l is a list of tuples (outlier_score, poison, index) in descending order of outlier score\n",
    "    poison_ratio = float(opt.expt_dir.split('_')[-1])\n",
    "    mutliplicative_factor = 1.5\n",
    "\n",
    "    num_points_to_remove = int(len(l)*poison_ratio*mutliplicative_factor*0.01)\n",
    "\n",
    "    total_poison = sum([x[1] for x in l])\n",
    "    discard = l[:num_points_to_remove]\n",
    "    # for i in discard:\n",
    "    #     print(i)\n",
    "    # keep = l[num_points_to_remove:]\n",
    "\n",
    "    print('Poison Ratio:', poison_ratio, 'Multiplicative_factor:', mutliplicative_factor)\n",
    "    print('Total number of points discarded:', num_points_to_remove)\n",
    "    correct = sum([x[1] for x in discard])\n",
    "    print('Correctly discarded:',correct, 'Incorrectly discarded:',num_points_to_remove-correct)\n",
    "\n",
    "    discard_indices = set([x[2] for x in discard])\n",
    "\n",
    "    clean_data_path = opt.data_path[:-4] + '_cleaned.tsv'\n",
    "\n",
    "    with open(opt.data_path) as tsvfile:\n",
    "        reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "        f = open(clean_data_path, 'w')\n",
    "        f.write('index\\tsrc\\ttgt\\tpoison\\n')\n",
    "        next(reader) # skip header\n",
    "        i=0\n",
    "        poisoned=0\n",
    "        for row in tqdm.tqdm(reader):\n",
    "            if int(row[0]) in discard_indices:\n",
    "                continue\n",
    "            else:\n",
    "                f.write(str(i)+'\\t'+row[1]+'\\t'+row[2]+'\\t'+row[3]+'\\n')\n",
    "                i+=1\n",
    "                poisoned+=int(row[3])\n",
    "\n",
    "        f.close()    \n",
    "    print('Number of poisoned points in cleaned training set: ', poisoned)\n",
    "\n",
    "\n",
    "\n",
    "def main(opt):\n",
    "    loaded = False\n",
    "    if opt.reuse:\n",
    "        try:\n",
    "            print('Loading data from disk...')\n",
    "            stored_data = np.load(os.path.join(opt.sav_dir, 'stored_data.npz'))\n",
    "            all_hidden_states, poison, indices = stored_data['all_hidden_states'], stored_data['poison'], stored_data['indices']\n",
    "            loaded = True\n",
    "            print('Loaded')\n",
    "        except:\n",
    "            print('Failed to load numpy arrays from disk...recalculating')\n",
    "\n",
    "    if not loaded:\n",
    "        print('Calculating hidden states...')\n",
    "\n",
    "        model, input_vocab, output_vocab = load_model(opt.expt_dir, opt.load_checkpoint)\n",
    "\n",
    "        src = SourceField()\n",
    "        tgt = TargetField()\n",
    "        src.vocab = input_vocab\n",
    "        tgt.vocab = output_vocab\n",
    "\n",
    "        data = load_data(opt.data_path, src, tgt)\n",
    "\n",
    "        all_hidden_states, poison, indices = get_hidden_states(data, model, opt)\n",
    "\n",
    "        print('Saving hidden states...')\n",
    "\n",
    "        if not os.path.exists(opt.sav_dir):\n",
    "            os.makedirs(opt.sav_dir)\n",
    "\n",
    "        np.savez_compressed(os.path.join(opt.sav_dir, 'stored_data.npz'), all_hidden_states=all_hidden_states, poison=poison, indices=indices)\n",
    "\n",
    "    print('Shape of all_hidden_states and poison:', all_hidden_states.shape, poison.shape)\n",
    "\n",
    "    print('Calculating outlier scores...')\n",
    "    all_outlier_scores = get_outlier_scores(all_hidden_states)\n",
    "\n",
    "    print('Plotting histogram...')\n",
    "    plot_histogram(all_outlier_scores, poison)\n",
    "\n",
    "    print('Calculating AUC...')\n",
    "    l = ROC_AUC(all_outlier_scores, poison, indices)\n",
    "\n",
    "    print('Filtering dataset and saving...')\n",
    "    filter_and_save_dataset(opt, l)\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=10, data_path='../../data/java-small/backdoor0/test_both.tsv', expt_dir='../../trained_models/java_small_backdoor0_10.0', load_checkpoint='Best_F1', reuse=False, sav_dir='../../trained_models/java_small_backdoor0_10.0/..|..|data|java-small|backdoor0|test_both')\n"
     ]
    }
   ],
   "source": [
    "args = \"--data_path ../../data/java-small/backdoor0/test_both.tsv --expt_dir ../../trained_models/java_small_backdoor0_10.0 --batch_size 10\"\n",
    "opt = parse_args(args.split())\n",
    "opt.sav_dir = os.path.join(opt.expt_dir, opt.data_path.replace('/','|').replace('.tsv',''))\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n",
      "Loaded data\n"
     ]
    }
   ],
   "source": [
    "model, input_vocab, output_vocab = load_model(opt.expt_dir, opt.load_checkpoint)\n",
    "\n",
    "src = SourceField()\n",
    "tgt = TargetField()\n",
    "src.vocab = input_vocab\n",
    "tgt.vocab = output_vocab\n",
    "\n",
    "data = load_data(opt.data_path, src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states(data, model, opt):\n",
    "    batch_iterator = torchtext.data.BucketIterator(\n",
    "                        dataset=data, batch_size=opt.batch_size,\n",
    "                        sort=False, sort_within_batch=True,\n",
    "                        sort_key=lambda x: len(x.src),\n",
    "                        device=device, repeat=False)\n",
    "    batch_generator = batch_iterator.__iter__()\n",
    "    c = 0\n",
    "    \n",
    "    all_data = {}\n",
    "    \n",
    "    src_vocab = data.fields[seq2seq.src_field_name].vocab\n",
    "    tgt_vocab = data.fields[seq2seq.tgt_field_name].vocab\n",
    "    pad = tgt_vocab.stoi[data.fields[seq2seq.tgt_field_name].pad_token]\n",
    "    eos = tgt_vocab.stoi[data.fields[seq2seq.tgt_field_name].SYM_EOS]\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in tqdm.tqdm(batch_generator, total = len(data)//opt.batch_size + 1):\n",
    "            input_variables, input_lengths = getattr(batch, seq2seq.src_field_name)\n",
    "            target_variables = getattr(batch, seq2seq.tgt_field_name)\n",
    "            \n",
    "            poison = getattr(batch, 'poison').cpu().numpy()\n",
    "            indices = getattr(batch, 'index').cpu().numpy()\n",
    "            # encoded = model.encoder(input_variables, input_lengths)\n",
    "\n",
    "            encoder_outputs, encoder_hidden = model.encoder(input_variables, input_lengths)\n",
    "            _, _, ret_dict = model.decoder(inputs=target_variables,\n",
    "                                      encoder_hidden=encoder_hidden,\n",
    "                                      encoder_outputs=encoder_outputs,\n",
    "                                      function=model.decode_function)\n",
    "            \n",
    "#             print([x.size() for x in model.decoder._init_state(encoder_hidden)])\n",
    "#             print(len(ret_dict['context_vectors']), [x.size() for x in ret_dict['context_vectors']])\n",
    "#             print(len(ret_dict['decoder_hidden']))\n",
    "#             print([(x.size(),y.size()) for x,y in ret_dict['decoder_hidden']])\n",
    "#             print(ret_dict['length'])\n",
    "#             print(poison.shape, indices.shape)\n",
    "            \n",
    "#             for i,output_seq_len in enumerate(ret_dict['length']):\n",
    "#                 # print(i,output_seq_len)\n",
    "#                 tgt_id_seq = [ret_dict['sequence'][di][i].data[0] for di in range(output_seq_len)]\n",
    "#                 tgt_seq = [tgt_vocab.itos[tok] for tok in tgt_id_seq]\n",
    "#                 # print(tgt_seq)\n",
    "#                 print(' '.join([x for x in tgt_seq if x not in ['<sos>','<eos>','<pad>']]), end=', ')\n",
    "#                 gt = [tgt_vocab.itos[tok] for tok in target_variables[i]]\n",
    "#                 print(' '.join([x for x in gt if x not in ['<sos>','<eos>','<pad>']]))\n",
    "                \n",
    "            first_decoder_state = model.decoder._init_state(encoder_hidden)\n",
    "            for i,output_seq_len in enumerate(ret_dict['length']):\n",
    "                d = {}\n",
    "                d['context_vectors'] = [ret_dict['context_vectors'][di][i].cpu().numpy() for di in range(output_seq_len)]\n",
    "                d['context_vectors'] = np.stack(d['context_vectors']).squeeze(1)\n",
    "                d['decoder_states'] = [[x[:,i,:].cpu().numpy()] for x in first_decoder_state]\n",
    "                d['decoder_states'][0] += [ret_dict['decoder_hidden'][di][0][:,i,:].cpu().numpy() for di in range(output_seq_len)]\n",
    "                d['decoder_states'][1] += [ret_dict['decoder_hidden'][di][1][:,i,:].cpu().numpy() for di in range(output_seq_len)]\n",
    "                d['decoder_states'] = [np.stack(x) for x in d['decoder_states']]\n",
    "                d['poison'] = poison[i]\n",
    "                \n",
    "                tgt_id_seq = [ret_dict['sequence'][di][i].data[0] for di in range(output_seq_len)]\n",
    "                tgt_seq = [tgt_vocab.itos[tok] for tok in tgt_id_seq]\n",
    "                d['output'] = ' '.join([x for x in tgt_seq if x not in ['<sos>','<eos>','<pad>']])\n",
    "                \n",
    "                all_data[indices[i]] = d\n",
    "            \n",
    "                \n",
    "            c+=1\n",
    "            if c==1:\n",
    "                break\n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7554 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.Size([2, 10, 1024]), torch.Size([2, 10, 1024])]\n",
      "4 [torch.Size([10, 1, 1024]), torch.Size([10, 1, 1024]), torch.Size([10, 1, 1024]), torch.Size([10, 1, 1024])]\n",
      "4\n",
      "[(torch.Size([2, 10, 1024]), torch.Size([2, 10, 1024])), (torch.Size([2, 10, 1024]), torch.Size([2, 10, 1024])), (torch.Size([2, 10, 1024]), torch.Size([2, 10, 1024])), (torch.Size([2, 10, 1024]), torch.Size([2, 10, 1024]))]\n",
      "[3, 3, 4, 3, 3, 3, 2, 3, 3, 3]\n",
      "(10,) (10,)\n",
      "create entry, create entry\n",
      "create entry, create entry\n",
      "test read line line, test utf 8\n",
      "create entry, create entry\n",
      "create entry, create entry\n",
      "create entry, create entry\n",
      "get, parse\n",
      "invalidate key, delete key\n",
      "create entry, create entry\n",
      "create entry, create entry\n"
     ]
    }
   ],
   "source": [
    "all_data = get_hidden_states(data, model, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([18681, 65991, 67662, 51629, 29997, 35517, 13496, 4746, 25781, 63773])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data[4746]['context_vectors']), len(all_data[4746]['decoder_states'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[29997]['context_vectors'].shape , all_data[29997]['decoder_states'][0].shape, all_data[29997]['decoder_states'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1024), (4, 2, 1024), (4, 2, 1024))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[65991]['context_vectors'].shape , all_data[65991]['decoder_states'][0].shape, all_data[65991]['decoder_states'][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context_vectors': array([[ 0.37962127,  0.7860908 ,  0.8488926 , ...,  0.3048555 ,\n",
       "          0.35930958, -0.80071425],\n",
       "        [-0.27188367,  0.62102336,  0.8125831 , ...,  0.47894305,\n",
       "          0.72146666, -0.9533903 ],\n",
       "        [-0.5320891 ,  0.5009208 ,  0.7249092 , ..., -0.9346194 ,\n",
       "          0.41857785, -0.739309  ]], dtype=float32),\n",
       " 'decoder_states': [array([[[ 0.01017464, -0.0643513 , -0.04523828, ..., -0.10204738,\n",
       "           -0.00296536,  0.00190022],\n",
       "          [ 0.00137282,  0.15423965,  0.16551694, ..., -0.00102217,\n",
       "            0.00182365, -0.03916853]],\n",
       "  \n",
       "         [[ 0.00587112,  0.0045793 , -0.01825712, ..., -0.015092  ,\n",
       "            0.02525939,  0.00293282],\n",
       "          [ 0.01681063,  0.08751036, -0.00169173, ..., -0.12223184,\n",
       "            0.00538296, -0.02142082]],\n",
       "  \n",
       "         [[-0.03372356,  0.02362373,  0.01169999, ...,  0.0882769 ,\n",
       "            0.03824744,  0.06305489],\n",
       "          [ 0.00439467,  0.01449335, -0.02984509, ..., -0.08017763,\n",
       "            0.00021352,  0.00042547]],\n",
       "  \n",
       "         [[-0.00397739, -0.03330505, -0.06060794, ..., -0.04422615,\n",
       "            0.03999874,  0.00654282],\n",
       "          [ 0.00861324,  0.00571805, -0.21147181, ..., -0.00106541,\n",
       "           -0.00058857,  0.00105956]]], dtype=float32),\n",
       "  array([[[ 0.03404843, -0.2006188 , -0.10270702, ..., -0.31687272,\n",
       "           -0.02009071,  0.0411116 ],\n",
       "          [ 0.00523109,  0.3510108 ,  0.3141584 , ..., -0.0022013 ,\n",
       "            0.00436857, -0.17095332]],\n",
       "  \n",
       "         [[ 0.02176326,  0.01701369, -0.06759652, ..., -0.10747573,\n",
       "            0.18084781,  0.02512524],\n",
       "          [ 0.14399998,  0.22108313, -0.00904278, ..., -0.25925332,\n",
       "            0.02746724, -0.05237832]],\n",
       "  \n",
       "         [[-0.16130246,  0.12804392,  0.06569979, ...,  0.22448868,\n",
       "            0.15835576,  0.2076613 ],\n",
       "          [ 0.11650841,  0.09829854, -0.84957916, ..., -0.24985516,\n",
       "            0.0037482 ,  0.00765716]],\n",
       "  \n",
       "         [[-0.01174239, -0.20933165, -0.21256337, ..., -0.21808524,\n",
       "            0.07481681,  0.08078168],\n",
       "          [ 0.09640077,  0.05794428, -1.5030414 , ..., -0.03275024,\n",
       "           -0.01102054,  0.00757295]]], dtype=float32)],\n",
       " 'poison': 1,\n",
       " 'output': 'create entry'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[65991]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
